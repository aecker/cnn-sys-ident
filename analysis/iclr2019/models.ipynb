{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models for ICLR 2019 paper\n",
    "\n",
    "### A rotation-equivariant convolutional neural network model of primary visual cortex\n",
    "*Alexander S. Ecker, Fabian H. Sinz, Emmanouil Froudarakis, Paul G. Fahey, Santiago A. Cadena, Edgar Y. Walker, Erick Cobos, Jacob Reimer, Andreas S. Tolias, Matthias Bethge*\n",
    "\n",
    "https://openreview.net/forum?id=H1fU8iAqKX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import tensorflow as tf, numpy as np, os, sys\n",
    "p = !pwd\n",
    "p = os.path.dirname(os.path.dirname(p[0]))\n",
    "if p not in sys.path:\n",
    "    sys.path.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_sys_ident.architectures.models import BaseModel, CorePlusReadoutModel\n",
    "from cnn_sys_ident.architectures.cores import StackedRotEquiHermiteConv2dCore\n",
    "from cnn_sys_ident.architectures.readouts import SpatialXFeatureJointL1Readout\n",
    "from cnn_sys_ident.architectures.training import Trainer\n",
    "from data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters used throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "NUM_ROTATIONS = 8\n",
    "UPSAMPLING = 2\n",
    "SHARED_BIASES = False\n",
    "FILTER_SIZE = [13, 5, 5]\n",
    "NUM_FILTERS = [16, 16, 16]\n",
    "STRIDE = [1, 1, 1]\n",
    "RATE = [1, 1, 1]\n",
    "PADDING = ['SAME', 'SAME', 'SAME']\n",
    "ACTIVATION_FN = ['soft', 'soft', 'none']\n",
    "REL_SMOOTH_WEIGHT = [1, 0.5, 0.5]\n",
    "REL_SPARSE_WEIGHT = [0, 1, 1]\n",
    "\n",
    "# Readout\n",
    "POSITIVE_FEATURE_WEIGHTS = False\n",
    "INIT_MASKS = 'rand'\n",
    "\n",
    "# Training\n",
    "VAL_STEPS = 50\n",
    "LEARNING_RATE = 0.002\n",
    "BATCH_SIZE = 256\n",
    "PATIENCE = 5\n",
    "LR_DECAY_STEPS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig. 2: Model comparison: number of features in last conv layer\n",
    "\n",
    "All models have the same basic architecture: three layers with 16–16–N features (N = 8 ... 48), each at 8 orientations. There are three hyperparameters that we optimize by random search (32 models each): smoothness of convolutional filters (`conv_smooth_weight` $\\in$ [0.001, 0.03]), group sparsity of convolutional filters (`conv_sparse_weight` $\\in$ [0.001, 0.1]) and sparsity of the readout (`readout_sparsity` $\\in$ [0.005, 0.03]). Below we specify the hyperparameters for the best model for each N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = [8, 12, 16, 20, 24, 28, 32, 40, 48]\n",
    "conv_smooth_weight = {\n",
    "    8:  0.00781004, 12: 0.00184694, 16: 0.0249692,\n",
    "    20: 0.0257738,  24: 0.00146371, 28: 0.0186784,\n",
    "    32: 0.026082,   40: 0.00232312, 48: 0.00129107}\n",
    "conv_sparse_weight = {\n",
    "    8:  0.0168574,  12: 0.0610123,  16: 0.0152482,\n",
    "    20: 0.0691215,  24: 0.00999698, 28: 0.0187448,\n",
    "    32: 0.0118641,  40: 0.0868334,  48: 0.0644271}\n",
    "readout_sparsity = {\n",
    "    8:  0.0156452,  12: 0.0153464,  16: 0.0170696,\n",
    "    20: 0.0141163,  24: 0.0131784,  28: 0.0124147,\n",
    "    32: 0.0161513,  40: 0.0115895,  48: 0.0163213}\n",
    "log_hash = {   # determines the seed of the random number generator\n",
    "    8:  '8d2912ce0669f4dcc4efa78b970e453c',\n",
    "    12: '4d2e43901a1be496a5e66dc9fec1ed14',\n",
    "    16: '647bb1d1bd02979996e492b5422eb95f',\n",
    "    20: '6babf3b3be2cbd8da50e091966f22e46',\n",
    "    24: '1e34d6f792b506630897ce84fe93a58c',\n",
    "    28: 'a653720bdd962f95b213156f25c80f31',\n",
    "    32: 'd23dd9d3a7149ecc72627115bb940e1e',\n",
    "    40: 'ba65e73469fe90109f22e8204557b646',\n",
    "    48: '37e70606daaa0b2ca13698fee329eec4'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_features in N:\n",
    "    base = BaseModel(\n",
    "        Dataset.load(),\n",
    "        log_dir='iclr2019-checkpoints-repro',\n",
    "        log_hash=log_hash[num_features]\n",
    "    )\n",
    "    core = StackedRotEquiHermiteConv2dCore(\n",
    "        base,\n",
    "        base.inputs,\n",
    "        num_rotations=NUM_ROTATIONS,\n",
    "        upsampling=UPSAMPLING,\n",
    "        shared_biases=SHARED_BIASES,\n",
    "        filter_size=FILTER_SIZE,\n",
    "        num_filters=[16, 16, num_features],\n",
    "        stride=STRIDE,\n",
    "        rate=RATE,\n",
    "        padding=PADDING,\n",
    "        activation_fn=ACTIVATION_FN,\n",
    "        rel_smooth_weight=REL_SMOOTH_WEIGHT,\n",
    "        rel_sparse_weight=REL_SPARSE_WEIGHT,\n",
    "        conv_smooth_weight=conv_smooth_weight[num_features],\n",
    "        conv_sparse_weight=conv_sparse_weight[num_features],\n",
    "    )\n",
    "    readout = SpatialXFeatureJointL1Readout(\n",
    "        base,\n",
    "        core.output,\n",
    "        positive_feature_weights=POSITIVE_FEATURE_WEIGHTS,\n",
    "        init_masks=INIT_MASKS,\n",
    "        readout_sparsity=readout_sparsity[num_features],\n",
    "    )\n",
    "    model = CorePlusReadoutModel(base, core, readout)\n",
    "    trainer = Trainer(base, model)\n",
    "    iter_num, val_loss, test_corr = trainer.fit(\n",
    "        val_steps=VAL_STEPS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        patience=PATIENCE,\n",
    "        lr_decay_steps=LR_DECAY_STEPS)\n",
    "    \n",
    "    trainer.compute_test_corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1: Performance of our proposed model and various baselines\n",
    "\n",
    "### Rotation-equivariant CNN 3x (16x8)\n",
    "\n",
    "Same as for N=16 above. Repeated here for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 16\n",
    "base = BaseModel(\n",
    "    Dataset.load(),\n",
    "    log_dir='iclr2019-checkpoints-repro',\n",
    "    log_hash=log_hash[num_features]\n",
    ")\n",
    "core = StackedRotEquiHermiteConv2dCore(\n",
    "    base,\n",
    "    base.inputs,\n",
    "    num_rotations=NUM_ROTATIONS,\n",
    "    upsampling=UPSAMPLING,\n",
    "    shared_biases=SHARED_BIASES,\n",
    "    filter_size=FILTER_SIZE,\n",
    "    num_filters=NUM_FILTERS,\n",
    "    stride=STRIDE,\n",
    "    rate=RATE,\n",
    "    padding=PADDING,\n",
    "    activation_fn=ACTIVATION_FN,\n",
    "    rel_smooth_weight=REL_SMOOTH_WEIGHT,\n",
    "    rel_sparse_weight=REL_SPARSE_WEIGHT,\n",
    "    conv_smooth_weight=conv_smooth_weight[num_features],\n",
    "    conv_sparse_weight=conv_sparse_weight[num_features],\n",
    ")\n",
    "readout = SpatialXFeatureJointL1Readout(\n",
    "    base,\n",
    "    core.output,\n",
    "    positive_feature_weights=POSITIVE_FEATURE_WEIGHTS,\n",
    "    init_masks=INIT_MASKS,\n",
    "    readout_sparsity=readout_sparsity[num_features],\n",
    ")\n",
    "model = CorePlusReadoutModel(base, core, readout)\n",
    "trainer = Trainer(base, model)\n",
    "iter_num, val_loss, test_corr = trainer.fit(\n",
    "    val_steps=VAL_STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    patience=PATIENCE,\n",
    "    lr_decay_steps=LR_DECAY_STEPS)\n",
    "\n",
    "trainer.compute_test_corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation-equivariant CNN, but with positive feature weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = BaseModel(\n",
    "    Dataset.load(),\n",
    "    log_dir='iclr2019-checkpoints-repro',\n",
    "    log_hash='a4de905100ac9b78c6a96e8d67f8adfe'\n",
    ")\n",
    "core = StackedRotEquiHermiteConv2dCore(\n",
    "    base,\n",
    "    base.inputs,\n",
    "    num_rotations=NUM_ROTATIONS,\n",
    "    upsampling=UPSAMPLING,\n",
    "    shared_biases=SHARED_BIASES,\n",
    "    filter_size=FILTER_SIZE,\n",
    "    num_filters=NUM_FILTERS,\n",
    "    stride=STRIDE,\n",
    "    rate=RATE,\n",
    "    padding=PADDING,\n",
    "    activation_fn=ACTIVATION_FN,\n",
    "    rel_smooth_weight=REL_SMOOTH_WEIGHT,\n",
    "    rel_sparse_weight=REL_SPARSE_WEIGHT,\n",
    "    conv_smooth_weight=0.00553383,\n",
    "    conv_sparse_weight=0.0715125,\n",
    ")\n",
    "readout = SpatialXFeatureJointL1Readout(\n",
    "    base,\n",
    "    core.output,\n",
    "    positive_feature_weights=True,\n",
    "    init_masks=INIT_MASKS,\n",
    "    readout_sparsity=0.0244531,\n",
    ")\n",
    "model = CorePlusReadoutModel(base, core, readout)\n",
    "trainer = Trainer(base, model)\n",
    "iter_num, val_loss, test_corr = trainer.fit(\n",
    "    val_steps=VAL_STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    patience=PATIENCE,\n",
    "    lr_decay_steps=LR_DECAY_STEPS)\n",
    "\n",
    "trainer.compute_test_corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation-equivariant CNN, but with non-sparse, L2-regularized feature weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_sys_ident.architectures.readouts import SpatialSparseXFeatureDenseSeparateReadout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = BaseModel(\n",
    "    Dataset.load(),\n",
    "    log_dir='iclr2019-checkpoints-repro',\n",
    "    log_hash='9ef7308edab3233c4d02d280ea37bc93'\n",
    ")\n",
    "core = StackedRotEquiHermiteConv2dCore(\n",
    "    base,\n",
    "    base.inputs,\n",
    "    num_rotations=NUM_ROTATIONS,\n",
    "    upsampling=UPSAMPLING,\n",
    "    shared_biases=SHARED_BIASES,\n",
    "    filter_size=FILTER_SIZE,\n",
    "    num_filters=NUM_FILTERS,\n",
    "    stride=STRIDE,\n",
    "    rate=RATE,\n",
    "    padding=PADDING,\n",
    "    activation_fn=ACTIVATION_FN,\n",
    "    rel_smooth_weight=REL_SMOOTH_WEIGHT,\n",
    "    rel_sparse_weight=REL_SPARSE_WEIGHT,\n",
    "    conv_smooth_weight=0.0141237,\n",
    "    conv_sparse_weight=0.00280391,\n",
    ")\n",
    "readout = SpatialSparseXFeatureDenseSeparateReadout(\n",
    "    base,\n",
    "    core.output,\n",
    "    positive_feature_weights=POSITIVE_FEATURE_WEIGHTS,\n",
    "    init_masks=INIT_MASKS,\n",
    "    mask_sparsity=0.0324413,\n",
    "    feature_l2=0.315181,\n",
    ")\n",
    "model = CorePlusReadoutModel(base, core, readout)\n",
    "trainer = Trainer(base, model)\n",
    "iter_num, val_loss, test_corr = trainer.fit(\n",
    "    val_steps=VAL_STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    patience=PATIENCE,\n",
    "    lr_decay_steps=LR_DECAY_STEPS)\n",
    "\n",
    "trainer.compute_test_corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular CNNs with cores of different sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_sys_ident.architectures.cores import StackedConv2dCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_filter_nums = [\n",
    "    [32, 32, 32],\n",
    "    [64, 64, 64],  # PARAMETERS SEEM TO BE OFF (performance 0.30)\n",
    "    [128, 128, 128],\n",
    "    [128, 128, 256],\n",
    "]\n",
    "conv_smooth_weights = [0.0151716, 0.00218237, 0.0277236, 0.0015324]\n",
    "conv_sparse_weights = [0.0219826, 0.0323365, 0.0650177, 0.007974]\n",
    "readout_sparsities = [0.0193531, 0.0261594, 0.0151648, 0.0179]\n",
    "log_hashes = [\n",
    "    '96c4d0cc8869d2b5a4297f13f2cdd422',\n",
    "    'b8c433730fc6d4753f6f910f697b7f4b',\n",
    "    '3bedbbd474249974eb309aeda76ca426',\n",
    "    'f4c477e777c48dac89e61feff11f4327',\n",
    "]\n",
    "for num_filters, conv_smooth_weight, conv_sparse_weight, readout_sparsity, log_hash in zip(\n",
    "        cnn_filter_nums, conv_smooth_weights, conv_sparse_weights, readout_sparsities, log_hashes):\n",
    "    base = BaseModel(\n",
    "        Dataset.load(),\n",
    "        log_dir='iclr2019-checkpoints-repro',\n",
    "        log_hash=log_hash\n",
    "    )\n",
    "    core = StackedConv2dCore(\n",
    "        base,\n",
    "        base.inputs,\n",
    "        filter_size=FILTER_SIZE,\n",
    "        num_filters=num_filters,\n",
    "        stride=STRIDE,\n",
    "        rate=RATE,\n",
    "        padding=PADDING,\n",
    "        activation_fn=ACTIVATION_FN,\n",
    "        rel_smooth_weight=REL_SMOOTH_WEIGHT,\n",
    "        rel_sparse_weight=REL_SPARSE_WEIGHT,\n",
    "        conv_smooth_weight=conv_smooth_weight,\n",
    "        conv_sparse_weight=conv_sparse_weight,\n",
    "    )\n",
    "    readout = SpatialXFeatureJointL1Readout(\n",
    "        base,\n",
    "        core.output,\n",
    "        positive_feature_weights=POSITIVE_FEATURE_WEIGHTS,\n",
    "        init_masks=INIT_MASKS,\n",
    "        readout_sparsity=readout_sparsity,\n",
    "    )\n",
    "    model = CorePlusReadoutModel(base, core, readout)\n",
    "    trainer = Trainer(base, model)\n",
    "    iter_num, val_loss, test_corr = trainer.fit(\n",
    "        val_steps=VAL_STEPS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        patience=PATIENCE,\n",
    "        lr_decay_steps=LR_DECAY_STEPS)\n",
    "\n",
    "    print(num_filters)\n",
    "    print(trainer.compute_test_corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control: Feature space generalizes to unseen neurons\n",
    "\n",
    "To show that our network learns common features of V1 neurons, we excluded half of the neurons when fitting the network. We then fixed the rotation-equivariant convolutional core and trained only the readout (spatial mask and feature weights) for the other half of the neurons. \n",
    "\n",
    "In terms of implementation, we insert a stop_gradient between the convolutional core and the readout for half of the neurons, which is done in the class for the readout (`SpatialXFeatureJointL1TransferReadout`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_sys_ident.architectures.cores import StackedRotEquiHermiteConv2dCore\n",
    "from cnn_sys_ident.architectures.readouts import SpatialXFeatureJointL1TransferReadout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = BaseModel(\n",
    "    Dataset.load(),\n",
    "    log_dir='iclr2019-checkpoints-repro',\n",
    "    log_hash='b8f78ead705cb02d09c01f9701067ba2'\n",
    ")\n",
    "core = StackedRotEquiHermiteConv2dCore(\n",
    "    base,\n",
    "    base.inputs,\n",
    "    num_rotations=NUM_ROTATIONS,\n",
    "    upsampling=UPSAMPLING,\n",
    "    shared_biases=SHARED_BIASES,\n",
    "    filter_size=FILTER_SIZE,\n",
    "    num_filters=NUM_FILTERS,\n",
    "    stride=STRIDE,\n",
    "    rate=RATE,\n",
    "    padding=PADDING,\n",
    "    activation_fn=ACTIVATION_FN,\n",
    "    rel_smooth_weight=REL_SMOOTH_WEIGHT,\n",
    "    rel_sparse_weight=REL_SPARSE_WEIGHT,\n",
    "    conv_smooth_weight=0.0112711,\n",
    "    conv_sparse_weight=0.0492937,\n",
    ")\n",
    "readout = SpatialXFeatureJointL1TransferReadout(\n",
    "    base,\n",
    "    core.output,\n",
    "    k_transfer=2,\n",
    "    positive_feature_weights=POSITIVE_FEATURE_WEIGHTS,\n",
    "    init_masks=INIT_MASKS,\n",
    "    readout_sparsity=0.020616,\n",
    ")\n",
    "model = CorePlusReadoutModel(base, core, readout)\n",
    "trainer = Trainer(base, model)\n",
    "iter_num, val_loss, test_corr = trainer.fit(\n",
    "    val_steps=VAL_STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    patience=PATIENCE,\n",
    "    lr_decay_steps=LR_DECAY_STEPS)\n",
    "\n",
    "trainer.compute_test_corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
